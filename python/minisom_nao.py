from __future__ import division

from numpy import genfromtxt, zeros, product, setdiff1d, arange, where,  unravel_index, tanh, savetxt
from parameters import param
from random import choice
from time import strftime

import random
import sys
import os
import pdb
import json
import cPickle as pickle

from minisom import MiniSom, Normalizer
from similar_vec import get_similar_vector
from dbg import *


def get_path():
    """
    Path to .dat file generated by NAO's babbling is given by a user in 
    terminal. If valid, return. 
    """
    nrarg = len(sys.argv)

    if nrarg<2:
        raise Exception('Please provide path to babbling knowledge base.')

    path = str(sys.argv[1])

    if not os.path.exists(path):
        raise Exception('Can\'t find the data.')

    return path

def read_data(path):
    """
    Return babbling coordinates for hands and joints
    """
    
    cols_hands = param['hands']
    cols_joints = param['joints']
    
    with open(path) as f:
        hands = genfromtxt(f, dtype=np.float, skip_header=2, usecols=cols_hands)
    
    with open(path) as f:    
        joints = genfromtxt(f, dtype=np.float, skip_header=2, usecols=cols_joints)
        
    data = {
        'hands': hands,
        'joints': joints
        }

    return data 

def train_som(data, offset=None):
    """
    offset: offset between points used for training
    """
    
    if offset:
        data = data[::offset, :]
    
    som = MiniSom(
        param['nr_rows'],
        param['nr_cols'], 
        data.shape[1], 
        data, 
        sigma=param['sigma'], 
        learning_rate=param['learning_rate'], 
        norm='minmax')
        
    #som.random_weights_init() # choose initial nodes from data points
    som.train_random(param['nr_epochs']) # random training
    
    return som

def hebbian_learning(som1, som2):
    s1, s2 = som1.weights.shape, som2.weights.shape
    hebb = zeros((param['nr_rows'], param['nr_cols'], \
        param['nr_rows'], param['nr_cols']))
    
    # minisom uses distances as activations, here we use sigmoid over distances
    # to get activations for hebbian learning
    f = lambda x: 1/(1+tanh(x))
    for dp1, dp2 in zip(som1.data, som2.data):
        act1 = som1.activate(dp1)
        act2 = som2.activate(dp2)
                
        idx1 = som1.winner(dp1)
        idx2 = som2.winner(dp2)
        
        hebb[idx1[0], idx1[1], idx2[0], idx2[1]] += param['eta'] * f(act1[idx1]) * f(act2[idx2])
        
    return hebb


def validate(som_hands, som_joints, frac):
    mse = 0
    _, w = som_joints.get_weights()
    unnorm = lambda x: x*som_joints.norm.ranges + som_joints.norm.mins    
    
    nr_pts = int(frac*som_hands.data.shape[0])
    for i in xrange(nr_pts):
        idx = random.randint(0, len(som_hands.data)-1) # l(sh.d) == l(sj.d)
        hands_view = som_hands.data[idx, :]
        
        # activate a neuron in the first map
        win_1 = som_hands.winner(hands_view)
        
        # find the neuron with the strongest connection in the second map
        win_2 = unravel_index(hebb[win_1[0], win_1[1], :, :].argmax(), \
            som_hands.weights.shape[:2])
            
        # get its weights
        joints = som_joints.weights[win_2[0], win_2[1], :]
        
        sim_joints, q, _ = get_similar_vector(w, som_joints.data[idx, :])
   
        
        dist = sum(som_joints.data[idx, :] - joints)
        mse += sum((som_joints.data[idx, :] - joints)**2)
    return mse/nr_pts
            
if __name__=="__main__":
    save = True
    savepath=''
    defstream = sys.stdout
    print param
    
    if save:    
        basepath = 'somconf/'
        dirname = strftime("%m_%d-%H_%M_%S")
        savepath = basepath + dirname + '/'
        os.mkdir(savepath)
        defstream = open(savepath + 'out.log', 'w')
        
    path = get_path()
    data = read_data(path)

    # train self-organizing maps
    som_hands = train_som(data['hands'])
    som_joints = train_som(data['joints'])
    
    defstream.write("Using %d data points for training.\n" % (som_hands.data.shape[0]))
    plot_and_save(som_hands, som_joints, savepath, param, offset=1)
    print "Done plotting!"

    dbg_print_inact(som_hands, som_joints, defstream)      
        
    # hebbian weights connecting maps
    hebb = hebbian_learning(som_hands, som_joints)

    #print_strongest_connections(hebb)    
    mse = validate(som_hands, som_joints, 0.8)    
    defstream.write('MSE: %f\n'%mse)
    
    # Project weights into original data space
    wh = Normalizer(som_hands.get_weights()[1]).minmax()
    wh *= som_hands.norm.ranges
    wh += som_hands.norm.mins
    
    wj = Normalizer(som_joints.get_weights()[1]).minmax()
    wj *= som_joints.norm.ranges
    wj += som_joints.norm.mins
    
    
    if save:
        defstream.close()        
        savestr = zip(['som1.csv',' som2.csv', 'hebb.csv'],
                       [wh, wj, hebb.reshape(wh.shape[0], wj.shape[0])])

        # Save weights
        for fname, dat in savestr:
            savetxt(savepath+fname, dat, delimiter=',')
    
        # Save simulation parameters
        with open(savepath + 'param.json', 'w') as f:
            json.dump(param, f)
        
        with open(savepath + 'soms.pkl', 'wb') as output:
            som_hands.neighborhood = None
            som_joints.neighborhood = None
            
            pickler = pickle.Pickler(output, -1)
            pickle.dump(som_hands, output)
            pickle.dump(som_joints, output)
        
